"""
MemoryMap Backend API

Tento modul poskytuje REST API pro aplikaci MemoryMap, kterÃ¡ umoÅ¾Åˆuje uklÃ¡dÃ¡nÃ­ a sprÃ¡vu
geograficky umÃ­stÄ›nÃ½ch vzpomÃ­nek. SouÄÃ¡st projektu vytvoÅ™enÃ©ho pro demonstraci
technickÃ½ch dovednostÃ­ pÅ™i pÅ™Ã­pravÄ› na pohovor.

HlavnÃ­ funkce:
- SprÃ¡va vzpomÃ­nek s geografickou lokacÃ­
- FulltextovÃ© vyhledÃ¡vÃ¡nÃ­ ve vzpomÃ­nkÃ¡ch
- ProstorovÃ© dotazy pro okolnÃ­ mÃ­sta

Autor: VytvoÅ™eno jako ukÃ¡zka dovednostÃ­ pro pohovor.
"""

from fastapi import FastAPI, HTTPException, Depends, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
import psycopg2  # Knihovna pro pÅ™ipojenÃ­ k PostgreSQL databÃ¡zi
from pydantic import BaseModel  # Pro validaci dat
from typing import List, Optional, Dict, Any  # Pro typovou kontrolu
import os
from dotenv import load_dotenv
from psycopg2.extras import RealDictCursor
import json
import time
import requests
from datetime import datetime

load_dotenv()

# VytvoÅ™enÃ­ FastAPI aplikace s vlastnÃ­m nÃ¡zvem
app = FastAPI(title="MemoryMap API")

# Konfigurace CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://stanislavhoracekmemorymap.streamlit.app",
        "http://localhost:8501",  # Pro lokÃ¡lnÃ­ vÃ½voj
        "https://localhost:8501",
        "https://memory-map.onrender.com",  # SprÃ¡vnÃ¡ Render.com URL
        "https://memorymap-api.onrender.com"  # PonechÃ¡me pro pÅ™Ã­pad
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def extract_keywords(text: str) -> List[str]:
    """JednoduchÃ¡ extrakce klÃ­ÄovÃ½ch slov z textu"""
    # RozdÄ›lÃ­me text na slova a vybereme slova delÅ¡Ã­ neÅ¾ 4 znaky
    words = [word.strip('.,!?()[]{}":;') for word in text.split()]
    keywords = [word for word in words if len(word) > 4]
    # VrÃ¡tÃ­me unikÃ¡tnÃ­ klÃ­ÄovÃ¡ slova
    return list(set(keywords))[:5]  # OmezÃ­me na max 5 klÃ­ÄovÃ½ch slov

# PromÄ›nnÃ¡ pro uloÅ¾enÃ­ connection poolu - globÃ¡lnÃ­ pro celou aplikaci
connection_pool = None

def get_db():
    """
    VytvoÅ™Ã­ a poskytuje pÅ™ipojenÃ­ k databÃ¡zi z connection poolu.
    """
    global connection_pool
    
    # ZjiÅ¡tÄ›nÃ­ URL databÃ¡ze z promÄ›nnÃ½ch prostÅ™edÃ­
    DATABASE_URL = None
    env_vars = [
        'DATABASE_URL',
        'RENDER_DATABASE_URL',
        'POSTGRES_URL',
        'PG_URL'
    ]
    
    for var in env_vars:
        if os.getenv(var):
            DATABASE_URL = os.getenv(var)
            print(f"PouÅ¾itÃ­ promÄ›nnÃ© {var} pro pÅ™ipojenÃ­ k databÃ¡zi")
            break
    
    if not DATABASE_URL:
        raise HTTPException(status_code=500, detail="Database configuration missing - no database URL found")
    
    try:
        # Ãšprava URL pro psycopg2 (pokud pouÅ¾Ã­vÃ¡ formÃ¡t postgres://)
        if DATABASE_URL.startswith('postgres://'):
            DATABASE_URL = DATABASE_URL.replace('postgres://', 'postgresql://', 1)
            print("URL konvertovÃ¡no z postgres:// na postgresql://")
        
        # Logging pro diagnostiku
        print(f"PÅ™ipojuji se k databÃ¡zi s URL zaÄÃ­najÃ­cÃ­m: {DATABASE_URL[:10]}...")
        
        # ZkusÃ­me pÅ™ipojenÃ­ s explicitnÃ­mi parametry
        try:
            from urllib.parse import urlparse
            parsed = urlparse(DATABASE_URL)
            
            # Extrahujeme parametry z URL
            host = parsed.hostname
            port = parsed.port or 5432  # ExplicitnÃ­ port 5432 pokud nenÃ­ v URL
            database = parsed.path[1:] if parsed.path else 'memorymap'
            user = parsed.username
            password = parsed.password
            
            print(f"PÅ™ipojuji s parametry: host={host}, port={port}, db={database}, user={user}")
            
            # ZkusÃ­me nejdÅ™Ã­ve bez SSL (jen pro test)
            try:
                conn = psycopg2.connect(
                    host=host,
                    port=port,
                    database=database,
                    user=user,
                    password=password,
                    connect_timeout=10
                )
                print("âœ… PÅ™ipojenÃ­ bez SSL ÃºspÄ›Å¡nÃ©!")
            except Exception as no_ssl_error:
                print(f"PÅ™ipojenÃ­ bez SSL selhalo: {str(no_ssl_error)}")
                print("ZkouÅ¡Ã­m s SSL...")
                # Fallback s SSL - pouÅ¾ijeme system trusted roots
                conn = psycopg2.connect(
                    host=host,
                    port=port,
                    database=database,
                    user=user,
                    password=password,
                    sslmode='verify-full',
                    sslcert=None,
                    sslkey=None,
                    sslrootcert='system',  # PouÅ¾ijeme system trusted roots
                    connect_timeout=10
                )
                print("âœ… PÅ™ipojenÃ­ s SSL ÃºspÄ›Å¡nÃ©!")
            conn.autocommit = True
            connection_pool = conn
            print("Connection pool ÃºspÄ›Å¡nÄ› vytvoÅ™en.")
            yield connection_pool
            return
        except Exception as e:
            print(f"Chyba pÅ™i vytvÃ¡Å™enÃ­ connection poolu: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Database connection failed: {str(e)}"
            )
        

            
    except Exception as e:
        print(f"Database connection error: {str(e)}")
        # DetailnÄ›jÅ¡Ã­ chybovÃ¡ zprÃ¡va pro diagnostiku
        raise HTTPException(
            status_code=500,
            detail=f"Database connection failed: {str(e)}"
        )

# ZÃ¡kladnÃ­ endpoint pro kontrolu, zda API bÄ›Å¾Ã­
@app.get("/")
async def root():
    return {"message": "MemoryMap API is running"}

# Definice struktury dat pro vstupnÃ­ data
class MemoryText(BaseModel):
    text: str  # Text vzpomÃ­nky
    location: str  # NÃ¡zev lokace
    latitude: float  # ZemÄ›pisnÃ¡ Å¡Ã­Å™ka
    longitude: float  # ZemÄ›pisnÃ¡ dÃ©lka
    source: Optional[str] = None  # VolitelnÃ½ zdroj vzpomÃ­nky
    date: Optional[str] = None  # VolitelnÃ© datum vzpomÃ­nky

# Alias pro MemoryText, kterÃ½ pouÅ¾Ã­vÃ¡me v novÃ©m endpointu
class MemoryCreate(BaseModel):
    text: str  # Text vzpomÃ­nky
    location: str  # NÃ¡zev lokace
    latitude: float  # ZemÄ›pisnÃ¡ Å¡Ã­Å™ka
    longitude: float  # ZemÄ›pisnÃ¡ dÃ©lka
    keywords: Optional[List[str]] = None  # VolitelnÃ¡ klÃ­ÄovÃ¡ slova
    source: Optional[str] = None  # VolitelnÃ½ zdroj vzpomÃ­nky
    date: Optional[str] = None  # VolitelnÃ© datum vzpomÃ­nky

# Definice struktury dat pro vÃ½stupnÃ­ data
class MemoryResponse(BaseModel):
    id: int  # IdentifikÃ¡tor vzpomÃ­nky v databÃ¡zi
    text: str  # Text vzpomÃ­nky
    location: str  # NÃ¡zev lokace
    keywords: List[str]  # Seznam klÃ­ÄovÃ½ch slov
    latitude: float  # ZemÄ›pisnÃ¡ Å¡Ã­Å™ka
    longitude: float  # ZemÄ›pisnÃ¡ dÃ©lka
    source: Optional[str] = None  # VolitelnÃ½ zdroj vzpomÃ­nky
    date: Optional[str] = None  # VolitelnÃ© datum vzpomÃ­nky
    
    class Config:
        orm_mode = True  # UmoÅ¾Åˆuje konverzi z databÃ¡zovÃ½ch objektÅ¯

# Endpoint pro analÃ½zu a uloÅ¾enÃ­ novÃ© vzpomÃ­nky
@app.post("/api/analyze", response_model=MemoryResponse)
async def analyze_text(data: MemoryText):
    conn = None
    try:
        # JednoduchÃ¡ extrakce klÃ­ÄovÃ½ch slov
        keywords = extract_keywords(data.text)
        
        # PÅ™ipojenÃ­ k databÃ¡zi
        conn = next(get_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Kontrola existence tabulky
            cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'memories')")
            table_exists = cur.fetchone()['exists']
            
            if not table_exists:
                # Pokud tabulka neexistuje, vytvoÅ™me ji
                try:
                    print("Tabulka memories neexistuje, vytvÃ¡Å™Ã­m ji...")
                    cur.execute('''
                        CREATE TABLE IF NOT EXISTS memories (
                            id SERIAL PRIMARY KEY,
                            text TEXT NOT NULL,
                            location VARCHAR(255) NOT NULL,
                            coordinates GEOGRAPHY(POINT, 4326) NOT NULL,
                            keywords TEXT[],
                            source TEXT,
                            date TEXT,
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        );
                    ''')
                    conn.commit()
                except Exception as create_error:
                    print(f"Chyba pÅ™i vytvÃ¡Å™enÃ­ tabulky: {str(create_error)}")
                    raise HTTPException(status_code=500, detail="Nelze vytvoÅ™it tabulku memories")
            
            # Kontrola PostGIS rozÅ¡Ã­Å™enÃ­
            try:
                cur.execute("SELECT PostGIS_Version()")
            except Exception as postgis_error:
                print(f"PostGIS nenÃ­ nainstalovÃ¡n: {str(postgis_error)}")
                raise HTTPException(status_code=500, detail="PostGIS rozÅ¡Ã­Å™enÃ­ nenÃ­ dostupnÃ©")
            
            try:
                # VloÅ¾enÃ­ vzpomÃ­nky do databÃ¡ze, vÄetnÄ› geografickÃ½ch dat
                cur.execute("""
                    INSERT INTO memories (text, location, keywords, source, date, coordinates)
                    VALUES (%s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326))
                    RETURNING id, text, location, keywords, source, date,
                            ST_X(coordinates::geometry) as longitude, ST_Y(coordinates::geometry) as latitude
                """, (data.text, data.location, keywords, data.source, data.date,
                      data.longitude, data.latitude))
                
                # ZÃ­skÃ¡nÃ­ vloÅ¾enÃ©ho zÃ¡znamu
                result = cur.fetchone()
                conn.commit()
                
                if result:
                    # PÅ™evod na oÄekÃ¡vanÃ½ formÃ¡t
                    memory = {
                        "id": result["id"],
                        "text": result["text"],
                        "location": result["location"],
                        "keywords": result["keywords"] if result["keywords"] else [],
                        "source": result["source"],
                        "date": result["date"],
                        "longitude": result["longitude"],
                        "latitude": result["latitude"]
                    }
                    return memory
                else:
                    raise HTTPException(status_code=500, detail="Failed to insert memory")
            except Exception as insert_error:
                print(f"Chyba pÅ™i vklÃ¡dÃ¡nÃ­ vzpomÃ­nky: {str(insert_error)}")
                conn.rollback()
                raise HTTPException(status_code=500, detail=f"Database error: {str(insert_error)}")
                
    except Exception as e:
        print(f"ObecnÃ¡ chyba pÅ™i analÃ½ze textu: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        if conn:
            conn.close()

# Endpoint pro zÃ­skÃ¡nÃ­ vÅ¡ech vzpomÃ­nek
@app.get("/api/memories", response_model=List[MemoryResponse])
async def get_memories():
    conn = None
    try:
        # PÅ™ipojenÃ­ k databÃ¡zi
        conn = next(get_db())
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Kontrola existence tabulky
            cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'memories')")
            table_exists = cur.fetchone()['exists']
            
            if not table_exists:
                print("Tabulka memories neexistuje, vracÃ­m prÃ¡zdnÃ½ seznam")
                return []
                
            # Kontrola PostGIS rozÅ¡Ã­Å™enÃ­
            try:
                cur.execute("SELECT PostGIS_Version()")
            except Exception as postgis_error:
                print(f"PostGIS nenÃ­ nainstalovÃ¡n: {str(postgis_error)}")
                return []
            
            try:
                # ZÃ­skÃ¡nÃ­ vÅ¡ech vzpomÃ­nek, vÄetnÄ› extrakce geografickÃ½ch souÅ™adnic
                cur.execute("""
                    SELECT id, text, location, keywords, source, date,
                           ST_X(coordinates::geometry) as longitude, ST_Y(coordinates::geometry) as latitude
                    FROM memories
                    ORDER BY created_at DESC
                """)
                
                # Transformace vÃ½sledkÅ¯ do seznamu objektÅ¯ podle oÄekÃ¡vanÃ©ho formÃ¡tu
                results = cur.fetchall()
                
                # PÅ™evod na oÄekÃ¡vanÃ½ formÃ¡t
                memories = []
                for row in results:
                    memory = dict(row)
                    memories.append(memory)
                
                return memories
            except Exception as e:
                print(f"Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ vzpomÃ­nek: {str(e)}")
                raise HTTPException(status_code=500, detail=str(e))
    
    except Exception as e:
        print(f"Chyba pÅ™i pÅ™ipojenÃ­ k databÃ¡zi: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/memories/{memory_id}", response_model=MemoryResponse)
async def get_memory(memory_id: int):
    """ZÃ­skÃ¡nÃ­ detailu konkrÃ©tnÃ­ vzpomÃ­nky"""
    conn = None
    try:
        # PÅ™ipojenÃ­ k databÃ¡zi
        conn = next(get_db())
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT id, text, location, keywords, source, date,
                       ST_X(coordinates::geometry) as longitude, ST_Y(coordinates::geometry) as latitude
                FROM memories
                WHERE id = %s
            """, (memory_id,))
            
            result = cur.fetchone()
            if result:
                # PÅ™evod na slovnÃ­k - jednoduÅ¡Å¡Ã­ zpÅ¯sob
                return dict(result)
            else:
                raise HTTPException(status_code=404, detail="Memory not found")
                
    except Exception as e:
        print(f"Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ vzpomÃ­nky {memory_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# DiagnostickÃ½ endpoint pro kontrolu promÄ›nnÃ½ch prostÅ™edÃ­
@app.get("/api/debug")
async def debug_info():
    # PÅ™Ã­prava informacÃ­ o promÄ›nnÃ½ch prostÅ™edÃ­ (bezpeÄnÃ½m zpÅ¯sobem)
    env_vars = os.environ.keys()
    db_env_vars = []
    
    # SbÃ­rÃ¡me vÅ¡echny promÄ›nnÃ© souvisejÃ­cÃ­ s databÃ¡zÃ­
    for key in env_vars:
        if 'DB' in key.upper() or 'DATABASE' in key.upper() or 'POSTGRES' in key.upper():
            db_env_vars.append(key)
    
    env_info = {
        "DATABASE_URL_EXISTS": os.getenv('DATABASE_URL') is not None,
        "DATABASE_RELATED_VARS": db_env_vars,
        "ENV_VARS_COUNT": len(list(env_vars)),
        "ENVIRONMENT": os.getenv('ENVIRONMENT', 'not set'),
        "PORT": os.getenv('PORT', 'not set')
    }
    
    # PÅ™idÃ¡me zaÄÃ¡tek kaÅ¾dÃ© databÃ¡zovÃ© promÄ›nnÃ© (bezpeÄnÄ›)
    for key in db_env_vars:
        value = os.getenv(key, '')
        if value:
            env_info[f"{key}_PREFIX"] = value[:10] + "..." if len(value) > 10 else value
    
    # Kontrola pÅ™ipojenÃ­ k databÃ¡zi
    db_connection_status = "Unknown"
    db_error = None
    db_details = {}
    
    # ZkusÃ­me najÃ­t a pouÅ¾Ã­t databÃ¡zovou URL
    database_url = None
    potential_db_vars = ['DATABASE_URL', 'RENDER_DATABASE_URL', 'POSTGRES_URL', 'PG_URL']
    
    for var in potential_db_vars:
        if os.getenv(var):
            database_url = os.getenv(var)
            db_details["used_env_var"] = var
            break
    
    try:
        if database_url:
            db_details["url_starts_with"] = database_url[:10] + "..."
            
            # AnalÃ½za URL
            from urllib.parse import urlparse
            try:
                parsed = urlparse(database_url)
                db_details["schema"] = parsed.scheme
                db_details["netloc"] = parsed.netloc
                db_details["path"] = parsed.path
                db_details["username_present"] = parsed.username is not None
                db_details["password_present"] = parsed.password is not None
                db_details["hostname"] = parsed.hostname
                db_details["port"] = parsed.port
            except Exception as parse_error:
                db_details["url_parse_error"] = str(parse_error)
            
            if database_url.startswith('postgres://'):
                modified_url = database_url.replace('postgres://', 'postgresql://', 1)
                db_details["modified_url_starts_with"] = modified_url[:10] + "..."
                database_url = modified_url
            
            try:
                conn = psycopg2.connect(database_url, connect_timeout=5)
                cur = conn.cursor()
                
                # Kontrola zÃ¡kladnÃ­ch informacÃ­ o databÃ¡zi
                cur.execute("SELECT version();")
                db_details["version"] = cur.fetchone()[0]
                
                # Kontrola PostGIS
                try:
                    cur.execute("SELECT PostGIS_Version();")
                    db_details["postgis_version"] = cur.fetchone()[0]
                except Exception as postgis_error:
                    db_details["postgis_error"] = str(postgis_error)
                
                # Kontrola tabulek
                cur.execute("""
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                """)
                db_details["tables"] = [row[0] for row in cur.fetchall()]
                
                # Zkontrolujeme tabulku memories
                try:
                    cur.execute("SELECT COUNT(*) FROM memories")
                    db_details["memories_count"] = cur.fetchone()[0]
                except Exception as table_error:
                    db_details["memories_table_error"] = str(table_error)
                
                conn.close()
                db_connection_status = "Connected"
                db_error = None
                
            except Exception as db_connect_error:
                db_connection_status = "Connection Failed"
                db_error = str(db_connect_error)
        else:
            db_connection_status = "No Database URL Found"
            db_error = "No suitable database URL environment variable found"
    except Exception as e:
        db_connection_status = "Failed"
        db_error = str(e)
    
    return {
        "status": "API is running",
        "environment": env_info,
        "database": {
            "status": db_connection_status,
            "error": db_error,
            "details": db_details
        }
    }

@app.get("/api/diagnostic")
async def diagnostic():
    """
    DiagnostickÃ½ endpoint pro ovÄ›Å™enÃ­ funkÄnosti API a stavu databÃ¡ze.
    VracÃ­ detailnÃ­ informace o:
    - Stavu pÅ™ipojenÃ­ k databÃ¡zi
    - PoÄtu vzpomÃ­nek v databÃ¡zi
    - StruktuÅ™e dat vzpomÃ­nek
    - Verzi PostGIS
    """
    conn = None
    result = {
        "status": "initializing",
        "api_version": "1.0.0",
        "timestamp": time.time(),
        "database": {
            "connected": False,
            "tables": [],
            "postgis_version": None,
            "memories_count": 0,
            "sample_memory": None
        },
        "errors": []
    }
    
    try:
        # PÅ™ipojenÃ­ k databÃ¡zi
        conn = next(get_db())
        result["database"]["connected"] = True
        result["status"] = "connected_to_db"
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # ZÃ­skÃ¡nÃ­ seznamu tabulek
            cur.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            """)
            tables = [row["table_name"] for row in cur.fetchall()]
            result["database"]["tables"] = tables
            
            # Kontrola existence tabulky memories
            memories_exists = "memories" in tables
            result["database"]["memories_table_exists"] = memories_exists
            
            # Kontrola PostGIS verze
            try:
                cur.execute("SELECT PostGIS_Version()")
                postgis_version = cur.fetchone()
                result["database"]["postgis_version"] = postgis_version["postgis_version"] if postgis_version else None
            except Exception as e:
                result["database"]["postgis_version"] = "not_installed"
                result["errors"].append(f"PostGIS error: {str(e)}")
            
            # Pokud tabulka memories existuje, zÃ­skÃ¡me poÄet vzpomÃ­nek a ukÃ¡zku
            if memories_exists:
                try:
                    # PoÄet vzpomÃ­nek
                    cur.execute("SELECT COUNT(*) as count FROM memories")
                    count = cur.fetchone()
                    result["database"]["memories_count"] = count["count"] if count else 0
                    
                    # VzorovÃ¡ vzpomÃ­nka s kompletnÃ­mi daty (pokud existuje)
                    if result["database"]["memories_count"] > 0:
                        cur.execute("""
                            SELECT id, text, location, keywords, source, date, coordinates,
                                   ST_X(coordinates::geometry) as longitude, 
                                   ST_Y(coordinates::geometry) as latitude,
                                   created_at
                            FROM memories
                            ORDER BY created_at DESC
                            LIMIT 1
                        """)
                        sample = cur.fetchone()
                        
                        # PÅ™evedeme na slovnÃ­k pro JSON vÃ½stup
                        if sample:
                            memory_dict = dict(sample)
                            # PÅ™evod PostgreSQL specifickÃ½ch typÅ¯ na string pro JSON vÃ½stup
                            memory_dict["coordinates"] = str(memory_dict["coordinates"])
                            memory_dict["created_at"] = str(memory_dict["created_at"])
                            result["database"]["sample_memory"] = memory_dict
                except Exception as e:
                    result["errors"].append(f"Error querying memories: {str(e)}")
        
        # PÅ™idÃ¡me informace o databÃ¡zovÃ©m URL (bezpeÄnÄ› maskovanÃ©)
        db_url = os.getenv('DATABASE_URL', 'not set')
        if db_url != 'not set':
            # Maskujeme citlivÃ© ÄÃ¡sti
            masked_url = mask_db_url(db_url)
            result["database"]["connection_string"] = masked_url
        
        # Pokud nejsou Å¾Ã¡dnÃ© chyby, oznaÄÃ­me jako ÃºspÄ›Å¡nÃ©
        if not result["errors"]:
            result["status"] = "healthy"
        
    except Exception as e:
        result["status"] = "error"
        result["errors"].append(str(e))
    
    return result

def mask_db_url(url):
    """Maskuje citlivÃ© ÄÃ¡sti databÃ¡zovÃ©ho URL"""
    if not url:
        return None
    
    try:
        # PostgreSQL URI formÃ¡t: postgresql://user:password@host:port/database
        parts = url.split('@')
        if len(parts) > 1:
            # MÃ¡me uÅ¾ivatelskÃ© jmÃ©no/heslo ÄÃ¡st
            credentials = parts[0].split('://')
            if len(credentials) > 1:
                protocol = credentials[0]
                user_pass = credentials[1].split(':')
                if len(user_pass) > 1:
                    # Maskujeme heslo
                    masked_url = f"{protocol}://{user_pass[0]}:****@{parts[1]}"
                    return masked_url
        
        # Pokud se formÃ¡t neshoduje s oÄekÃ¡vanÃ½m, vracÃ­me obecnÃ© maskovÃ¡nÃ­
        return url.replace('postgres://', 'postgres://****:****@')
    except:
        # V pÅ™Ã­padÄ› problÃ©mu s parsovÃ¡nÃ­m vracÃ­me bezpeÄnou verzi
        return "database_url_format_error"

# Endpoint pro pÅ™idÃ¡nÃ­ novÃ© vzpomÃ­nky
@app.post("/api/memories", response_model=MemoryResponse, status_code=201)
async def add_memory(memory: MemoryCreate):
    conn = None
    try:
        # PÅ™ipojenÃ­ k databÃ¡zi
        conn = next(get_db())
        
        # ExtrahovÃ¡nÃ­ klÃ­ÄovÃ½ch slov, pokud nebyla poskytnuta pÅ™Ã­mo
        keywords = memory.keywords if memory.keywords else extract_keywords(memory.text)
        
        # VytvoÅ™enÃ­ SQL dotazu s odolnostÃ­ proti SQL injection pomocÃ­ parametrizovanÃ©ho dotazu
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # Kontrola existence tabulky a vytvoÅ™enÃ­, pokud neexistuje
            cur.execute("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'memories')")
            table_exists = cur.fetchone()['exists']
            
            if not table_exists:
                try:
                    print("Tabulka memories neexistuje, vytvÃ¡Å™Ã­m...")
                    # Nejprve zkontrolujeme, zda je PostGIS nainstalovÃ¡n
                    try:
                        cur.execute("SELECT PostGIS_Version()")
                    except:
                        # Pokud PostGIS nenÃ­ nainstalovÃ¡n, pokusÃ­me se ho pÅ™idat
                        try:
                            cur.execute("CREATE EXTENSION IF NOT EXISTS postgis;")
                            conn.commit()
                            print("PostGIS rozÅ¡Ã­Å™enÃ­ ÃºspÄ›Å¡nÄ› pÅ™idÃ¡no.")
                        except Exception as e:
                            print(f"Nelze pÅ™idat PostGIS rozÅ¡Ã­Å™enÃ­: {str(e)}")
                            raise HTTPException(
                                status_code=500,
                                detail=f"PostGIS rozÅ¡Ã­Å™enÃ­ nenÃ­ dostupnÃ©: {str(e)}"
                            )
                    
                    # VytvoÅ™enÃ­ tabulky memories
                    cur.execute("""
                        CREATE TABLE memories (
                            id SERIAL PRIMARY KEY,
                            text TEXT NOT NULL,
                            location VARCHAR(255) NOT NULL,
                            coordinates GEOMETRY(POINT, 4326) NOT NULL,
                            keywords TEXT[] DEFAULT '{}',
                            source VARCHAR(255),
                            date DATE,
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        );
                    """)
                    conn.commit()
                    print("Tabulka memories ÃºspÄ›Å¡nÄ› vytvoÅ™ena.")
                except Exception as e:
                    print(f"Chyba pÅ™i vytvÃ¡Å™enÃ­ tabulky: {str(e)}")
                    conn.rollback()
                    raise HTTPException(
                        status_code=500,
                        detail=f"Nelze vytvoÅ™it tabulku memories: {str(e)}"
                    )
            
            try:
                # VloÅ¾enÃ­ novÃ© vzpomÃ­nky do databÃ¡ze
                cur.execute("""
                    INSERT INTO memories (text, location, coordinates, keywords, source, date)
                    VALUES (%s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s, %s)
                    RETURNING id, text, location, keywords, source, date, 
                              ST_X(coordinates) as longitude, ST_Y(coordinates) as latitude;
                """, (
                    memory.text,
                    memory.location,
                    memory.longitude,
                    memory.latitude,
                    keywords,
                    memory.source,
                    memory.date
                ))
                
                # ZÃ­skÃ¡nÃ­ vloÅ¾enÃ©ho zÃ¡znamu
                new_memory = cur.fetchone()
                conn.commit()
                
                if new_memory:
                    # PÅ™evod na slovnÃ­k a vrÃ¡cenÃ­ jako odpovÄ›Ä
                    return dict(new_memory)
                else:
                    raise HTTPException(status_code=500, detail="Failed to retrieve the newly added memory")
                
            except Exception as e:
                # Rollback v pÅ™Ã­padÄ› chyby
                conn.rollback()
                print(f"Chyba pÅ™i vklÃ¡dÃ¡nÃ­ vzpomÃ­nky: {str(e)}")
                raise HTTPException(status_code=500, detail=str(e))
                
    except Exception as e:
        print(f"ObecnÃ¡ chyba pÅ™i pÅ™idÃ¡vÃ¡nÃ­ vzpomÃ­nky: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    
    # NepÅ™idÃ¡vÃ¡me finally blok, kterÃ½ by zavÃ­ral pÅ™ipojenÃ­, protoÅ¾e pouÅ¾Ã­vÃ¡me connection pool

# SpuÅ¡tÄ›nÃ­ aplikace, pokud je tento soubor spuÅ¡tÄ›n pÅ™Ã­mo
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

# ============================================================================
# RISK ANALYST FEATURE - NovÃ© modely a endpointy pro VW Group
# ============================================================================

# PÅ™Ã­mÃ© pÅ™ipojenÃ­ k risk analyst databÃ¡zi
def get_risk_db():
    """PÅ™ipojenÃ­ k risk analyst databÃ¡zi"""
    import psycopg2
    import os
    from typing import Generator
    
    # ZkusÃ­me environment variable, pak fallback
    database_url = os.getenv('RISK_DATABASE_URL')
    
    if database_url:
        # PouÅ¾ijeme DATABASE_URL format
        try:
            conn = psycopg2.connect(database_url, sslmode='require')
            yield conn
        except Exception as e:
            print(f"Chyba pÅ™i pÅ™ipojenÃ­ pÅ™es DATABASE_URL: {str(e)}")
            raise
    else:
        # Fallback na hardcoded hodnoty
        try:
            conn = psycopg2.connect(
                host="dpg-d2a54tp5pdvs73acu64g-a.frankfurt-postgres.render.com",
                port="5432",
                dbname="risk_analyst",
                user="risk_analyst_user",
                password="uN3Zogp6tvoTmnjNV4owD92Nnm6UlGkf",
                sslmode='require'
            )
            yield conn
        except Exception as e:
            print(f"Chyba pÅ™i pÅ™ipojenÃ­ k risk analyst databÃ¡zi: {str(e)}")
            raise

# NovÃ© Pydantic modely pro risk events
class RiskEventCreate(BaseModel):
    title: str
    description: Optional[str] = None
    latitude: float
    longitude: float
    event_type: str  # 'flood', 'protest', 'supply_chain', 'geopolitical'
    severity: str  # 'low', 'medium', 'high', 'critical'
    source: str  # 'chmi_api', 'rss', 'manual', 'copernicus'
    url: Optional[str] = None

class RiskEventResponse(BaseModel):
    id: int
    title: str
    description: Optional[str] = None
    latitude: float
    longitude: float
    event_type: str
    severity: str
    source: str
    url: Optional[str] = None
    scraped_at: Optional[str] = None
    created_at: str

    class Config:
        orm_mode = True

class SupplierResponse(BaseModel):
    id: int
    name: str
    latitude: float
    longitude: float
    category: Optional[str] = None
    risk_level: str
    created_at: str

    class Config:
        orm_mode = True

class RiskAnalysisResponse(BaseModel):
    event_count: int
    high_risk_count: int
    risk_score: float

# ============================================================================
# RISK EVENTS API ENDPOINTS
# ============================================================================

@app.get("/api/risks")
async def get_risk_events(
    event_type: Optional[str] = None,
    severity: Optional[str] = None,
    lat: Optional[float] = None,
    lon: Optional[float] = None,
    radius_km: Optional[int] = 50
):
    """ZÃ­skÃ¡ risk events s filtry"""
    conn = None
    try:
        print("ğŸ” SpouÅ¡tÃ­m get_risk_events...")
        conn = next(get_risk_db())
        print("âœ… PÅ™ipojenÃ­ k databÃ¡zi OK")
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # ZÃ¡kladnÃ­ dotaz
            query = """
                SELECT id, title, description, 
                       ST_X(location::geometry) as longitude, 
                       ST_Y(location::geometry) as latitude,
                       event_type, severity, source, url, 
                       scraped_at, created_at
                FROM risk_events
                WHERE 1=1
            """
            params = []
            
            # PÅ™idÃ¡nÃ­ filtrÅ¯
            if event_type:
                query += " AND event_type = %s"
                params.append(event_type)
            
            if severity:
                query += " AND severity = %s"
                params.append(severity)
            
            # GeografickÃ½ filtr
            if lat is not None and lon is not None:
                query += """
                    AND ST_DWithin(
                        location::geography, 
                        ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography, 
                        %s * 1000
                    )
                """
                params.extend([lon, lat, radius_km])
            
            query += " ORDER BY created_at DESC"
            
            print(f"ğŸ” Executing query: {query}")
            print(f"ğŸ” With params: {params}")
            
            cur.execute(query, params)
            results = cur.fetchall()
            
            print(f"âœ… Found {len(results)} results")
            
            # Debug: vypÃ­Å¡eme prvnÃ­ vÃ½sledek
            if results:
                first_result = dict(results[0])
                print(f"ğŸ” First result keys: {list(first_result.keys())}")
                print(f"ğŸ” First result: {first_result}")
            
            # Konverze na response modely
            response_data = []
            for row in results:
                row_dict = dict(row)
                # ZajistÃ­me sprÃ¡vnÃ© datovÃ© typy
                row_dict['latitude'] = float(row_dict['latitude'])
                row_dict['longitude'] = float(row_dict['longitude'])
                row_dict['id'] = int(row_dict['id'])
                response_data.append(row_dict)
            
            print(f"âœ… Returning {len(response_data)} items")
            return response_data
            
    except Exception as e:
        print(f"âŒ Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ risk events: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")

@app.post("/api/risks", response_model=RiskEventResponse, status_code=201)
async def create_risk_event(risk: RiskEventCreate):
    """VytvoÅ™Ã­ novÃ½ risk event"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                INSERT INTO risk_events (title, description, location, event_type, severity, source, url)
                VALUES (%s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s, %s, %s)
                RETURNING id, title, description, 
                          ST_X(location::geometry) as longitude, 
                          ST_Y(location::geometry) as latitude,
                          event_type, severity, source, url, 
                          scraped_at, created_at
            """, (
                risk.title,
                risk.description,
                risk.longitude,
                risk.latitude,
                risk.event_type,
                risk.severity,
                risk.source,
                risk.url
            ))
            
            new_risk = cur.fetchone()
            conn.commit()
            
            return dict(new_risk)
            
    except Exception as e:
        print(f"Chyba pÅ™i vytvÃ¡Å™enÃ­ risk event: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/risks/{risk_id}", response_model=RiskEventResponse)
async def get_risk_event(risk_id: int):
    """ZÃ­skÃ¡ konkrÃ©tnÃ­ risk event"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT id, title, description, 
                       ST_X(location::geometry) as longitude, 
                       ST_Y(location::geometry) as latitude,
                       event_type, severity, source, url, 
                       scraped_at, created_at
                FROM risk_events
                WHERE id = %s
            """, (risk_id,))
            
            result = cur.fetchone()
            if not result:
                raise HTTPException(status_code=404, detail="Risk event not found")
            
            return dict(result)
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ risk event: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# SUPPLIERS API ENDPOINTS
# ============================================================================

@app.get("/api/suppliers")
async def get_suppliers():
    """ZÃ­skÃ¡ vÅ¡echny dodavatele VW Group"""
    conn = None
    try:
        print("ğŸ” SpouÅ¡tÃ­m get_suppliers...")
        conn = next(get_risk_db())
        print("âœ… PÅ™ipojenÃ­ k databÃ¡zi OK")
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT id, name, 
                       ST_X(location::geometry) as longitude, 
                       ST_Y(location::geometry) as latitude,
                       category, risk_level, created_at
                FROM vw_suppliers
                ORDER BY name
            """)
            
            results = cur.fetchall()
            print(f"âœ… Found {len(results)} suppliers")
            
            # Konverze na response data
            response_data = []
            for row in results:
                row_dict = dict(row)
                # ZajistÃ­me sprÃ¡vnÃ© datovÃ© typy
                row_dict['latitude'] = float(row_dict['latitude'])
                row_dict['longitude'] = float(row_dict['longitude'])
                row_dict['id'] = int(row_dict['id'])
                # Konvertujeme datetime na string
                if row_dict['created_at']:
                    row_dict['created_at'] = str(row_dict['created_at'])
                response_data.append(row_dict)
            
            print(f"âœ… Returning {len(response_data)} suppliers")
            return response_data
            
    except Exception as e:
        print(f"âŒ Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ dodavatelÅ¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# RISK ANALYSIS API ENDPOINTS
# ============================================================================

@app.get("/api/analysis/risk-map")
async def get_risk_map():
    """VrÃ¡tÃ­ data pro risk mapu - vÅ¡echny risk events a dodavatele"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # ZÃ­skÃ¡nÃ­ vÅ¡ech risk events
            cur.execute("""
                SELECT id, title, description, 
                       ST_X(location::geometry) as longitude, 
                       ST_Y(location::geometry) as latitude,
                       event_type, severity, source, url, 
                       created_at
                FROM risk_events
                ORDER BY created_at DESC
            """)
            risk_events_raw = cur.fetchall()
            
            # Konverze risk events
            risk_events = []
            for row in risk_events_raw:
                row_dict = dict(row)
                row_dict['latitude'] = float(row_dict['latitude'])
                row_dict['longitude'] = float(row_dict['longitude'])
                row_dict['id'] = int(row_dict['id'])
                if row_dict['created_at']:
                    row_dict['created_at'] = str(row_dict['created_at'])
                risk_events.append(row_dict)
            
            # ZÃ­skÃ¡nÃ­ vÅ¡ech dodavatelÅ¯
            cur.execute("""
                SELECT id, name, 
                       ST_X(location::geometry) as longitude, 
                       ST_Y(location::geometry) as latitude,
                       category, risk_level, created_at
                FROM vw_suppliers
                ORDER BY name
            """)
            suppliers_raw = cur.fetchall()
            
            # Konverze suppliers
            suppliers = []
            for row in suppliers_raw:
                row_dict = dict(row)
                row_dict['latitude'] = float(row_dict['latitude'])
                row_dict['longitude'] = float(row_dict['longitude'])
                row_dict['id'] = int(row_dict['id'])
                if row_dict['created_at']:
                    row_dict['created_at'] = str(row_dict['created_at'])
                suppliers.append(row_dict)
            
            return {
                "risk_events": risk_events,
                "suppliers": suppliers
            }
            
    except Exception as e:
        print(f"Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ risk map data: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analysis/supplier-risk", response_model=RiskAnalysisResponse)
async def analyze_supplier_risk(
    lat: float,
    lon: float,
    radius_km: int = 50
):
    """AnalÃ½za rizik pro dodavatele v danÃ©m okolÃ­"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT * FROM calculate_risk_in_radius(%s, %s, %s)
            """, (lat, lon, radius_km))
            
            result = cur.fetchone()
            if result:
                return {
                    "event_count": result['event_count'],
                    "high_risk_count": result['high_risk_count'],
                    "risk_score": float(result['risk_score'])
                }
            else:
                return {
                    "event_count": 0,
                    "high_risk_count": 0,
                    "risk_score": 0.0
                }
            
    except Exception as e:
        print(f"Chyba pÅ™i analÃ½ze rizik dodavatele: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analysis/statistics")
async def get_risk_statistics():
    """Statistiky rizik"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # CelkovÃ½ poÄet risk events
            cur.execute("SELECT COUNT(*) as total_events FROM risk_events")
            total_events = cur.fetchone()['total_events']
            
            # PoÄet podle typu
            cur.execute("""
                SELECT event_type, COUNT(*) as count
                FROM risk_events
                GROUP BY event_type
                ORDER BY count DESC
            """)
            events_by_type = [dict(row) for row in cur.fetchall()]
            
            # PoÄet podle zÃ¡vaÅ¾nosti
            cur.execute("""
                SELECT severity, COUNT(*) as count
                FROM risk_events
                GROUP BY severity
                ORDER BY count DESC
            """)
            events_by_severity = [dict(row) for row in cur.fetchall()]
            
            # PoÄet dodavatelÅ¯
            cur.execute("SELECT COUNT(*) as total_suppliers FROM vw_suppliers")
            total_suppliers = cur.fetchone()['total_suppliers']
            
            return {
                "total_events": total_events,
                "total_suppliers": total_suppliers,
                "events_by_type": events_by_type,
                "events_by_severity": events_by_severity
            }
            
    except Exception as e:
        print(f"Chyba pÅ™i zÃ­skÃ¡vÃ¡nÃ­ statistik: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================================================
# WEB SCRAPING ENDPOINTS (placeholder pro budoucÃ­ implementaci)
# ============================================================================

@app.get("/api/scrape/chmi")
async def scrape_chmi_floods():
    """Scrape CHMI API pro zÃ¡plavovÃ© vÃ½strahy"""
    try:
        print("ğŸ” SpouÅ¡tÃ­m CHMI scraper...")
        
        # FunkÄnÃ­ CHMI API endpointy podle dokumentace
        chmi_endpoints = [
            "https://hydro.chmi.cz/hpps/hpps_act.php",
            "https://hydro.chmi.cz/hpps/hpps_act_quick.php", 
            "https://hydro.chmi.cz/hpps/hpps_act_quick.php?q=1",
            "https://hydro.chmi.cz/hpps/hpps_act_quick.php?q=2",
            "https://hydro.chmi.cz/hpps/hpps_act_quick.php?q=3"
        ]
        
        scraped_events = []
        
        for endpoint in chmi_endpoints:
            try:
                print(f"ğŸŒŠ Testuji CHMI endpoint: {endpoint}")
                response = requests.get(endpoint, timeout=30)
                
                if response.status_code == 200:
                    print(f"âœ… ÃšspÄ›Å¡nÃ© pÅ™ipojenÃ­ k: {endpoint}")
                    data = response.text
                    print(f"ğŸ“Š ZÃ­skanÃ¡ data: {len(data)} znakÅ¯")
                    
                    # Parsujeme skuteÄnÃ¡ CHMI data
                    events = parse_chmi_data(data, endpoint)
                    scraped_events.extend(events)
                    print(f"âœ… Nalezeno {len(events)} udÃ¡lostÃ­ z {endpoint}")
                    break  # PouÅ¾ijeme prvnÃ­ funkÄnÃ­ endpoint
                else:
                    print(f"âš ï¸ Endpoint {endpoint} vrÃ¡til status {response.status_code}")
                    
            except requests.RequestException as e:
                print(f"âŒ Chyba pÅ™i stahovÃ¡nÃ­ z {endpoint}: {str(e)}")
                continue
        
        if not scraped_events:
            print("âš ï¸ Å½Ã¡dnÃ½ CHMI endpoint nefunguje, Å¾Ã¡dnÃ¡ data nebudou uloÅ¾ena")
            # NenÃ­ fallback data - vrÃ¡tÃ­me prÃ¡zdnÃ½ seznam
            scraped_events = []
        
        # UloÅ¾Ã­me events do databÃ¡ze
        conn = None
        saved_count = 0
        
        try:
            conn = next(get_risk_db())
            
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                for event in scraped_events:
                    # Kontrola duplikÃ¡tÅ¯ podle title a source
                    cur.execute("""
                        SELECT id FROM risk_events 
                        WHERE title = %s AND source = 'chmi_api'
                        LIMIT 1
                    """, (event['title'],))
                    
                    if cur.fetchone():
                        print(f"â­ï¸ DuplikÃ¡t nalezen: {event['title']}")
                        continue
                    
                    # VloÅ¾enÃ­ novÃ©ho eventu
                    cur.execute("""
                        INSERT INTO risk_events (title, description, location, event_type, severity, source, url, scraped_at)
                        VALUES (%s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s, %s, %s, %s)
                        RETURNING id
                    """, (
                        event['title'],
                        event['description'],
                        event['longitude'],
                        event['latitude'],
                        event['event_type'],
                        event['severity'],
                        event['source'],
                        event['url'],
                        datetime.now()
                    ))
                    
                    event_id = cur.fetchone()['id']
                    saved_count += 1
                    print(f"âœ… UloÅ¾en event ID {event_id}: {event['title']}")
                
                conn.commit()
                
        except Exception as e:
            print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ do databÃ¡ze: {str(e)}")
            if conn:
                conn.rollback()
            raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")
        finally:
            if conn:
                conn.close()
        
        return {
            "message": f"CHMI scraper dokonÄen",
            "status": "success",
            "scraped_count": len(scraped_events),
            "saved_count": saved_count,
            "source_url": endpoint if 'endpoint' in locals() else "multiple_endpoints",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ NeoÄekÃ¡vanÃ¡ chyba v CHMI scraperu: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Scraper error: {str(e)}")

def parse_chmi_data(data: str, source_url: str) -> List[Dict]:
    """Parsuje skuteÄnÃ¡ CHMI data"""
    events = []
    
    try:
        # HledÃ¡me klÃ­ÄovÃ¡ slova v CHMI odpovÄ›di
        keywords = ['zÃ¡plav', 'povodn', 'vÃ½strah', 'vltav', 'morav', 'sÃ¡zav', 'berounk']
        
        for keyword in keywords:
            if keyword.lower() in data.lower():
                # VytvoÅ™Ã­me event na zÃ¡kladÄ› nalezenÃ©ho klÃ­ÄovÃ©ho slova
                event = create_chmi_event_from_keyword(keyword, source_url)
                if event:
                    events.append(event)
        
        # Pokud nenajdeme Å¾Ã¡dnÃ© klÃ­ÄovÃ© slovo, zkusÃ­me parsovat JSON/XML strukturu
        if not events:
            events = parse_chmi_structured_data(data, source_url)
            
        print(f"ğŸ” ParsovÃ¡no {len(events)} udÃ¡lostÃ­ z CHMI dat")
        return events
        
    except Exception as e:
        print(f"âŒ Chyba pÅ™i parsovÃ¡nÃ­ CHMI dat: {str(e)}")
        return []

def create_chmi_event_from_keyword(keyword: str, source_url: str) -> Dict:
    """VytvoÅ™Ã­ event na zÃ¡kladÄ› klÃ­ÄovÃ©ho slova"""
    keyword_mapping = {
        'zÃ¡plav': {
            'title': f"ZÃ¡plavovÃ¡ vÃ½straha - {get_region_name(keyword)}",
            'description': f"CHMI vydalo zÃ¡plavovou vÃ½strahu pro {get_region_name(keyword)}",
            'latitude': 49.5,
            'longitude': 14.5,
            'severity': 'high'
        },
        'povodn': {
            'title': f"PovodÅˆovÃ¡ vÃ½straha - {get_region_name(keyword)}",
            'description': f"CHMI varuje pÅ™ed povodnÄ›mi v {get_region_name(keyword)}",
            'latitude': 49.2,
            'longitude': 14.4,
            'severity': 'critical'
        },
        'vÃ½strah': {
            'title': f"HydrologickÃ¡ vÃ½straha - {get_region_name(keyword)}",
            'description': f"CHMI vydalo hydrologickou vÃ½strahu pro {get_region_name(keyword)}",
            'latitude': 50.0,
            'longitude': 14.3,
            'severity': 'medium'
        },
        'vltav': {
            'title': "VÃ½straha - Vltava",
            'description': "Vzestup hladiny Vltavy v Praze a okolÃ­",
            'latitude': 50.0755,
            'longitude': 14.4378,
            'severity': 'high'
        },
        'morav': {
            'title': "VÃ½straha - Morava",
            'description': "CHMI varuje pÅ™ed zÃ¡plavami na MoravÄ›",
            'latitude': 49.1951,
            'longitude': 16.6068,
            'severity': 'critical'
        }
    }
    
    if keyword in keyword_mapping:
        event_data = keyword_mapping[keyword]
        return {
            "title": event_data['title'],
            "description": event_data['description'],
            "latitude": event_data['latitude'],
            "longitude": event_data['longitude'],
            "event_type": "flood",
            "severity": event_data['severity'],
            "source": "chmi_api",
            "url": source_url
        }
    
    return None

def get_region_name(keyword: str) -> str:
    """VrÃ¡tÃ­ nÃ¡zev regionu na zÃ¡kladÄ› klÃ­ÄovÃ©ho slova"""
    regions = {
        'zÃ¡plav': 'JiÅ¾nÃ­ ÄŒechy',
        'povodn': 'StÅ™ednÃ­ ÄŒechy', 
        'vÃ½strah': 'Praha',
        'vltav': 'Praha',
        'morav': 'Morava'
    }
    return regions.get(keyword, 'ÄŒeskÃ¡ republika')

def parse_chmi_structured_data(data: str, source_url: str) -> List[Dict]:
    """Parsuje strukturovanÃ¡ CHMI data (JSON/XML)"""
    events = []
    
    try:
        # ZkusÃ­me parsovat jako JSON
        import json
        json_data = json.loads(data)
        
        # HledÃ¡me relevantnÃ­ data v JSON struktuÅ™e
        if isinstance(json_data, dict):
            events = parse_chmi_json(json_data, source_url)
        elif isinstance(json_data, list):
            for item in json_data:
                if isinstance(item, dict):
                    event = parse_chmi_json_item(item, source_url)
                    if event:
                        events.append(event)
                        
    except json.JSONDecodeError:
        # NenÃ­ JSON, zkusÃ­me XML nebo HTML
        events = parse_chmi_html(data, source_url)
    except Exception as e:
        print(f"âŒ Chyba pÅ™i parsovÃ¡nÃ­ strukturovanÃ½ch dat: {str(e)}")
    
    return events

def parse_chmi_json(data: Dict, source_url: str) -> List[Dict]:
    """Parsuje CHMI JSON data"""
    events = []
    
    # HledÃ¡me klÃ­ÄovÃ¡ slova v JSON struktuÅ™e
    json_str = str(data).lower()
    
    if 'zÃ¡plav' in json_str or 'povodn' in json_str:
        events.append({
            "title": "ZÃ¡plavovÃ¡ vÃ½straha - CHMI data",
            "description": "CHMI vydalo zÃ¡plavovou vÃ½strahu na zÃ¡kladÄ› aktuÃ¡lnÃ­ch dat",
            "latitude": 49.5,
            "longitude": 14.5,
            "event_type": "flood",
            "severity": "high",
            "source": "chmi_api",
            "url": source_url
        })
    
    return events

def parse_chmi_json_item(item: Dict, source_url: str) -> Dict:
    """Parsuje jednotlivÃ½ JSON item z CHMI"""
    # Implementace parsovÃ¡nÃ­ jednotlivÃ©ho JSON objektu
    return None

def parse_chmi_html(data: str, source_url: str) -> List[Dict]:
    """Parsuje CHMI HTML data"""
    events = []
    
    # HledÃ¡me klÃ­ÄovÃ¡ slova v HTML
    if 'zÃ¡plav' in data.lower() or 'povodn' in data.lower():
        events.append({
            "title": "ZÃ¡plavovÃ¡ vÃ½straha - CHMI web",
            "description": "CHMI vydalo zÃ¡plavovou vÃ½strahu na zÃ¡kladÄ› webovÃ½ch dat",
            "latitude": 49.5,
            "longitude": 14.5,
            "event_type": "flood",
            "severity": "high",
            "source": "chmi_api",
            "url": source_url
        })
    
    return events

# Fallback data funkce byla odstranÄ›na - aplikace funguje pouze s reÃ¡lnÃ½mi daty

@app.get("/api/scrape/rss")
async def scrape_rss_feeds():
    """Scrape RSS feeds pro novinky a udÃ¡losti"""
    try:
        print("ğŸ” SpouÅ¡tÃ­m RSS scraper...")
        
        # RSS feeds pro novinky a udÃ¡losti
        rss_feeds = [
            "https://www.novinky.cz/rss",
            "https://www.seznamzpravy.cz/rss",
            "https://hn.cz/rss/2",
            "https://www.irozhlas.cz/rss/irozhlas"
        ]
        
        scraped_events = []
        
        for feed_url in rss_feeds:
            try:
                print(f"ğŸ“° Stahuji RSS feed: {feed_url}")
                response = requests.get(feed_url, timeout=30)
                response.raise_for_status()
                
                # Parsujeme skuteÄnÃ½ RSS XML
                events = parse_rss_feed(response.text, feed_url)
                scraped_events.extend(events)
                print(f"âœ… RSS feed zpracovÃ¡n: {len(events)} udÃ¡lostÃ­")
                
            except requests.RequestException as e:
                print(f"âš ï¸ Chyba pÅ™i stahovÃ¡nÃ­ RSS feedu {feed_url}: {str(e)}")
                continue
        
        # UloÅ¾Ã­me events do databÃ¡ze
        conn = None
        saved_count = 0
        
        try:
            conn = next(get_risk_db())
            
            with conn.cursor(cursor_factory=RealDictCursor) as cur:
                for event in scraped_events:
                    # Kontrola duplikÃ¡tÅ¯ podle title a source
                    cur.execute("""
                        SELECT id FROM risk_events 
                        WHERE title = %s AND source = 'rss'
                        LIMIT 1
                    """, (event['title'],))
                    
                    if cur.fetchone():
                        print(f"â­ï¸ DuplikÃ¡t nalezen: {event['title']}")
                        continue
                    
                    # VloÅ¾enÃ­ novÃ©ho eventu
                    cur.execute("""
                        INSERT INTO risk_events (title, description, location, event_type, severity, source, url, scraped_at)
                        VALUES (%s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s, %s, %s, %s)
                        RETURNING id
                    """, (
                        event['title'],
                        event['description'],
                        event['longitude'],
                        event['latitude'],
                        event['event_type'],
                        event['severity'],
                        event['source'],
                        event['url'],
                        datetime.now()
                    ))
                    
                    event_id = cur.fetchone()['id']
                    saved_count += 1
                    print(f"âœ… UloÅ¾en event ID {event_id}: {event['title']}")
                
                conn.commit()
                
        except Exception as e:
            print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ do databÃ¡ze: {str(e)}")
            if conn:
                conn.rollback()
            raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")
        finally:
            if conn:
                conn.close()
        
        return {
            "message": f"RSS scraper dokonÄen",
            "status": "success",
            "scraped_count": len(scraped_events),
            "saved_count": saved_count,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ NeoÄekÃ¡vanÃ¡ chyba v RSS scraperu: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Scraper error: {str(e)}")

def parse_rss_feed(rss_xml: str, feed_url: str) -> List[Dict]:
    """Parsuje RSS XML feed a hledÃ¡ relevantnÃ­ udÃ¡losti"""
    events = []
    
    try:
        import xml.etree.ElementTree as ET
        
        # Parsujeme XML
        root = ET.fromstring(rss_xml)
        
        # HledÃ¡me item elementy
        items = root.findall('.//item')
        
        for item in items:
            # ZÃ­skÃ¡me title a description
            title_elem = item.find('title')
            description_elem = item.find('description')
            
            if title_elem is not None:
                title = title_elem.text or ""
                description = description_elem.text if description_elem is not None else ""
                
                # HledÃ¡me relevantnÃ­ klÃ­ÄovÃ¡ slova
                event = analyze_rss_item_for_risk(title, description, feed_url)
                if event:
                    events.append(event)
        
        print(f"ğŸ” AnalyzovÃ¡no {len(items)} RSS poloÅ¾ek, nalezeno {len(events)} relevantnÃ­ch udÃ¡lostÃ­")
        return events
        
    except ET.ParseError as e:
        print(f"âŒ Chyba pÅ™i parsovÃ¡nÃ­ RSS XML: {str(e)}")
        return []
    except Exception as e:
        print(f"âŒ NeoÄekÃ¡vanÃ¡ chyba pÅ™i parsovÃ¡nÃ­ RSS: {str(e)}")
        return []

def analyze_rss_item_for_risk(title: str, description: str, feed_url: str) -> Dict:
    """Analyzuje RSS poloÅ¾ku a hledÃ¡ rizikovÃ© udÃ¡losti"""
    
    # KlÃ­ÄovÃ¡ slova pro rÅ¯znÃ© typy rizik
    risk_keywords = {
        'protest': ['protest', 'demonstrace', 'stÃ¡vka', 'manifestace', 'nepokoje'],
        'supply_chain': ['doprava', 'dÃ¡lnice', 'silnice', 'uzavÃ­rka', 'nehoda', 'havÃ¡rie', 'blokÃ¡da'],
        'geopolitical': ['politika', 'vlÃ¡da', 'parlament', 'napÄ›tÃ­', 'konflikt', 'diplomacie'],
        'flood': ['zÃ¡plavy', 'povodnÄ›', 'deÅ¡tÄ›', 'voda', 'vltava', 'morava', 'Å™eka']
    }
    
    # Kombinujeme title a description pro analÃ½zu
    text = f"{title} {description}".lower()
    
    # HledÃ¡me klÃ­ÄovÃ¡ slova
    for event_type, keywords in risk_keywords.items():
        for keyword in keywords:
            if keyword in text:
                return create_rss_event(title, description, event_type, keyword, feed_url)
    
    return None

def create_rss_event(title: str, description: str, event_type: str, keyword: str, feed_url: str) -> Dict:
    """VytvoÅ™Ã­ event na zÃ¡kladÄ› RSS poloÅ¾ky"""
    
    # MapovÃ¡nÃ­ typÅ¯ udÃ¡lostÃ­ na severity
    severity_mapping = {
        'protest': 'medium',
        'supply_chain': 'high', 
        'geopolitical': 'medium',
        'flood': 'high'
    }
    
    # MapovÃ¡nÃ­ na lokace podle klÃ­ÄovÃ½ch slov
    location_mapping = {
        'praha': (50.0755, 14.4378),
        'brno': (49.1951, 16.6068),
        'ostrava': (49.8175, 18.2625),
        'plzeÅˆ': (49.7475, 13.3776),
        'liberec': (50.7663, 15.0543),
        'olomouc': (49.5938, 17.2507),
        'ÄeskÃ© budÄ›jovice': (48.9745, 14.4747),
        'hradec krÃ¡lovÃ©': (50.2092, 15.8327),
        'pardubice': (50.0343, 15.7812),
        'zlÃ­n': (49.2264, 17.6683)
    }
    
    # HledÃ¡me lokaci v textu
    latitude, longitude = 50.0, 14.3  # VÃ½chozÃ­ - stÅ™ed ÄŒR
    for location_name, coords in location_mapping.items():
        if location_name in title.lower() or location_name in description.lower():
            latitude, longitude = coords
            break
    
    return {
        "title": title[:100],  # OmezÃ­me dÃ©lku title
        "description": description[:200] if description else f"UdÃ¡lost souvisejÃ­cÃ­ s {keyword}",
        "latitude": latitude,
        "longitude": longitude,
        "event_type": event_type,
        "severity": severity_mapping.get(event_type, 'medium'),
        "source": "rss",
        "url": feed_url
    }

@app.get("/api/scrape/run-all")
async def run_all_scrapers():
    """SpustÃ­ vÅ¡echny scrapers najednou"""
    try:
        print("ğŸš€ SpouÅ¡tÃ­m vÅ¡echny scrapers...")
        
        results = {
            "chmi": None,
            "rss": None,
            "total_events_saved": 0,
            "start_time": datetime.now().isoformat()
        }
        
        # SpustÃ­me CHMI scraper
        try:
            print("ğŸŒŠ SpouÅ¡tÃ­m CHMI scraper...")
            chmi_response = await scrape_chmi_floods()
            results["chmi"] = chmi_response
            results["total_events_saved"] += chmi_response.get("saved_count", 0)
            print("âœ… CHMI scraper dokonÄen")
        except Exception as e:
            print(f"âŒ CHMI scraper selhal: {str(e)}")
            results["chmi"] = {"error": str(e), "status": "failed"}
        
        # SpustÃ­me RSS scraper
        try:
            print("ğŸ“° SpouÅ¡tÃ­m RSS scraper...")
            rss_response = await scrape_rss_feeds()
            results["rss"] = rss_response
            results["total_events_saved"] += rss_response.get("saved_count", 0)
            print("âœ… RSS scraper dokonÄen")
        except Exception as e:
            print(f"âŒ RSS scraper selhal: {str(e)}")
            results["rss"] = {"error": str(e), "status": "failed"}
        
        results["end_time"] = datetime.now().isoformat()
        results["status"] = "completed"
        
        return {
            "message": "VÅ¡echny scrapers dokonÄeny",
            "status": "success",
            "results": results
        }
        
    except Exception as e:
        print(f"âŒ NeoÄekÃ¡vanÃ¡ chyba pÅ™i spouÅ¡tÄ›nÃ­ scraperÅ¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Scraper orchestration error: {str(e)}") 

@app.get("/api/debug-env")
async def debug_environment():
    """Debug endpoint pro ovÄ›Å™enÃ­ environment variables"""
    import os
    
    return {
        "RISK_DATABASE_URL": os.getenv('RISK_DATABASE_URL', 'NOT_SET'),
        "DATABASE_URL": os.getenv('DATABASE_URL', 'NOT_SET'),
        "PYTHON_VERSION": os.getenv('PYTHON_VERSION', 'NOT_SET'),
        "PORT": os.getenv('PORT', 'NOT_SET'),
        "message": "Environment variables debug"
    } 

# ============================================================================
# ADVANCED RISK ANALYSIS ENDPOINTS
# ============================================================================

@app.get("/api/analysis/river-flood-simulation")
async def river_flood_simulation(
    supplier_id: Optional[int] = None,
    river_name: Optional[str] = None,
    flood_level_m: Optional[float] = None
):
    """Simulace zÃ¡plav a jejich dopadu na dodavatele"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            # ZÃ­skÃ¡nÃ­ dat o Å™ekÃ¡ch a dodavatelÃ­ch
            if supplier_id:
                # AnalÃ½za konkrÃ©tnÃ­ho dodavatele
                cur.execute("""
                    SELECT name, category, risk_level,
                           ST_X(location::geometry) as longitude,
                           ST_Y(location::geometry) as latitude
                    FROM vw_suppliers 
                    WHERE id = %s
                """, [supplier_id])
                supplier = cur.fetchone()
                
                if not supplier:
                    return {"error": "Dodavatel nenalezen"}
                
                # Simulace zÃ¡plav pro danou lokaci
                flood_risk = calculate_flood_risk(
                    supplier['latitude'], 
                    supplier['longitude'], 
                    flood_level_m or 2.0
                )
                
                return {
                    "supplier": dict(supplier),
                    "flood_simulation": flood_risk,
                    "risk_assessment": {
                        "flood_probability": flood_risk['probability'],
                        "impact_level": flood_risk['impact_level'],
                        "mitigation_needed": flood_risk['mitigation_needed']
                    }
                }
            else:
                # AnalÃ½za vÅ¡ech dodavatelÅ¯ v rizikovÃ½ch oblastech
                cur.execute("""
                    SELECT id, name, category, risk_level,
                           ST_X(location::geometry) as longitude,
                           ST_Y(location::geometry) as latitude
                    FROM vw_suppliers 
                    WHERE risk_level IN ('high', 'critical')
                    ORDER BY risk_level DESC
                """)
                suppliers = cur.fetchall()
                
                flood_analysis = []
                for supplier in suppliers:
                    flood_risk = calculate_flood_risk(
                        supplier['latitude'], 
                        supplier['longitude'], 
                        flood_level_m or 2.0
                    )
                    flood_analysis.append({
                        "supplier": dict(supplier),
                        "flood_risk": flood_risk
                    })
                
                return {
                    "total_suppliers_analyzed": len(flood_analysis),
                    "high_risk_suppliers": len([s for s in flood_analysis if s['flood_risk']['impact_level'] == 'high']),
                    "flood_analysis": flood_analysis
                }
                
    except Exception as e:
        print(f"âŒ Chyba pÅ™i simulaci zÃ¡plav: {str(e)}")
        return {"error": f"Chyba pÅ™i simulaci: {str(e)}"}
    finally:
        if conn:
            conn.close()

@app.get("/api/analysis/geographic-risk-assessment")
async def geographic_risk_assessment(
    lat: float,
    lon: float,
    radius_km: int = 50
):
    """KomplexnÃ­ geografickÃ¡ analÃ½za rizik pro danou lokaci"""
    try:
        # AnalÃ½za vzdÃ¡lenosti od Å™ek
        river_analysis = analyze_river_proximity(lat, lon, radius_km)
        
        # AnalÃ½za nadmoÅ™skÃ© vÃ½Å¡ky
        elevation_analysis = analyze_elevation_profile(lat, lon)
        
        # AnalÃ½za historickÃ½ch udÃ¡lostÃ­
        historical_analysis = analyze_historical_events(lat, lon, radius_km)
        
        # KombinovanÃ© hodnocenÃ­ rizik
        combined_risk = calculate_combined_risk(
            river_analysis, 
            elevation_analysis, 
            historical_analysis
        )
        
        return {
            "location": {"latitude": lat, "longitude": lon},
            "analysis_radius_km": radius_km,
            "river_analysis": river_analysis,
            "elevation_analysis": elevation_analysis,
            "historical_analysis": historical_analysis,
            "combined_risk_assessment": combined_risk
        }
        
    except Exception as e:
        print(f"âŒ Chyba pÅ™i geografickÃ© analÃ½ze: {str(e)}")
        return {"error": f"Chyba pÅ™i analÃ½ze: {str(e)}"}

@app.get("/api/analysis/supply-chain-impact")
async def supply_chain_impact_analysis(
    supplier_id: Optional[int] = None,
    event_type: Optional[str] = None
):
    """AnalÃ½za dopadu udÃ¡lostÃ­ na dodavatelskÃ½ Å™etÄ›zec"""
    conn = None
    try:
        conn = next(get_risk_db())
        
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            if supplier_id:
                # AnalÃ½za konkrÃ©tnÃ­ho dodavatele
                cur.execute("""
                    SELECT id, name, category, risk_level,
                           ST_X(location::geometry) as longitude,
                           ST_Y(location::geometry) as latitude
                    FROM vw_suppliers 
                    WHERE id = %s
                """, [supplier_id])
                supplier = cur.fetchone()
                
                if not supplier:
                    return {"error": "Dodavatel nenalezen"}
                
                # AnalÃ½za rizikovÃ½ch udÃ¡lostÃ­ v okolÃ­
                cur.execute("""
                    SELECT COUNT(*) as total_events,
                           COUNT(*) FILTER (WHERE severity IN ('high', 'critical')) as high_risk_events,
                           COUNT(*) FILTER (WHERE event_type = %s) as specific_type_events
                    FROM risk_events
                    WHERE ST_DWithin(
                        location::geography,
                        ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography,
                        50 * 1000
                    )
                """, [event_type or 'flood', supplier['longitude'], supplier['latitude']])
                
                risk_stats = cur.fetchone()
                
                # Simulace dopadu na dodavatelskÃ½ Å™etÄ›zec
                impact_analysis = simulate_supply_chain_impact(
                    supplier, risk_stats, event_type
                )
                
                return {
                    "supplier": dict(supplier),
                    "risk_statistics": dict(risk_stats),
                    "supply_chain_impact": impact_analysis
                }
            else:
                # AnalÃ½za celÃ©ho dodavatelskÃ©ho Å™etÄ›zce
                cur.execute("""
                    SELECT id, name, category, risk_level,
                           ST_X(location::geometry) as longitude,
                           ST_Y(location::geometry) as latitude
                    FROM vw_suppliers
                    ORDER BY risk_level DESC
                """)
                suppliers = cur.fetchall()
                
                chain_analysis = []
                for supplier in suppliers:
                    # AnalÃ½za rizik pro kaÅ¾dÃ©ho dodavatele
                    cur.execute("""
                        SELECT COUNT(*) as nearby_events,
                               COUNT(*) FILTER (WHERE severity IN ('high', 'critical')) as critical_events
                        FROM risk_events
                        WHERE ST_DWithin(
                            location::geography,
                            ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography,
                            50 * 1000
                        )
                    """, [supplier['longitude'], supplier['latitude']])
                    
                    risk_stats = cur.fetchone()
                    impact = simulate_supply_chain_impact(
                        supplier, risk_stats, event_type
                    )
                    
                    chain_analysis.append({
                        "supplier": dict(supplier),
                        "risk_analysis": dict(risk_stats),
                        "impact_assessment": impact
                    })
                
                return {
                    "total_suppliers": len(chain_analysis),
                    "high_risk_suppliers": len([s for s in chain_analysis if s['supplier']['risk_level'] in ['high', 'critical']]),
                    "supply_chain_analysis": chain_analysis
                }
                
    except Exception as e:
        print(f"âŒ Chyba pÅ™i analÃ½ze dodavatelskÃ©ho Å™etÄ›zce: {str(e)}")
        return {"error": f"Chyba pÅ™i analÃ½ze: {str(e)}"}
    finally:
        if conn:
            conn.close()

# ============================================================================
# HELPER FUNCTIONS FOR ADVANCED ANALYSIS
# ============================================================================

def calculate_flood_risk(lat: float, lon: float, flood_level_m: float) -> dict:
    """VÃ½poÄet rizika zÃ¡plav pro danou lokaci"""
    # Simulace na zÃ¡kladÄ› nadmoÅ™skÃ© vÃ½Å¡ky a vzdÃ¡lenosti od Å™ek
    base_elevation = 200  # PrÅ¯mÄ›rnÃ¡ nadmoÅ™skÃ¡ vÃ½Å¡ka ÄŒR
    river_distance = calculate_river_distance(lat, lon)
    
    # VÃ½poÄet pravdÄ›podobnosti zÃ¡plav
    if river_distance < 1.0:  # MÃ©nÄ› neÅ¾ 1km od Å™eky
        probability = 0.8
        impact_level = "critical"
    elif river_distance < 5.0:  # 1-5km od Å™eky
        probability = 0.6
        impact_level = "high"
    elif river_distance < 10.0:  # 5-10km od Å™eky
        probability = 0.3
        impact_level = "medium"
    else:
        probability = 0.1
        impact_level = "low"
    
    # Ãšprava podle nadmoÅ™skÃ© vÃ½Å¡ky
    if base_elevation < 150:
        probability *= 1.5
    elif base_elevation > 400:
        probability *= 0.5
    
    return {
        "probability": min(probability, 1.0),
        "impact_level": impact_level,
        "river_distance_km": river_distance,
        "elevation_m": base_elevation,
        "flood_level_m": flood_level_m,
        "mitigation_needed": probability > 0.5
    }

def calculate_river_distance(lat: float, lon: float) -> float:
    """VÃ½poÄet vzdÃ¡lenosti od nejbliÅ¾Å¡Ã­ Å™eky (simulace)"""
    # HlavnÃ­ Å™eky ÄŒR s pÅ™ibliÅ¾nÃ½mi souÅ™adnicemi
    rivers = [
        {"name": "Vltava", "lat": 50.0755, "lon": 14.4378},
        {"name": "Labe", "lat": 50.2092, "lon": 15.8327},
        {"name": "Morava", "lat": 49.1951, "lon": 16.6068},
        {"name": "OhÅ™e", "lat": 50.231, "lon": 12.880},
        {"name": "Berounka", "lat": 49.7475, "lon": 13.3776}
    ]
    
    min_distance = float('inf')
    for river in rivers:
        distance = ((lat - river['lat'])**2 + (lon - river['lon'])**2)**0.5
        # PÅ™evod na km (pÅ™ibliÅ¾nÄ›)
        distance_km = distance * 111
        min_distance = min(min_distance, distance_km)
    
    return min_distance

def analyze_river_proximity(lat: float, lon: float, radius_km: int) -> dict:
    """AnalÃ½za blÃ­zkosti Å™ek"""
    river_distance = calculate_river_distance(lat, lon)
    
    return {
        "nearest_river_distance_km": river_distance,
        "flood_risk_zone": river_distance < 5.0,
        "high_risk_zone": river_distance < 2.0,
        "risk_level": "high" if river_distance < 5.0 else "medium" if river_distance < 10.0 else "low"
    }

def analyze_elevation_profile(lat: float, lon: float) -> dict:
    """AnalÃ½za nadmoÅ™skÃ© vÃ½Å¡ky (simulace)"""
    # Simulace nadmoÅ™skÃ© vÃ½Å¡ky na zÃ¡kladÄ› souÅ™adnic
    base_elevation = 200 + (lat - 50.0) * 100 + (lon - 14.0) * 50
    
    return {
        "elevation_m": base_elevation,
        "flood_vulnerability": "high" if base_elevation < 200 else "medium" if base_elevation < 300 else "low",
        "terrain_type": "lowland" if base_elevation < 200 else "hills" if base_elevation < 400 else "mountains"
    }

def analyze_historical_events(lat: float, lon: float, radius_km: int) -> dict:
    """AnalÃ½za historickÃ½ch udÃ¡lostÃ­ v okolÃ­"""
    # Simulace na zÃ¡kladÄ› lokace
    historical_floods = 2 if lat < 50.0 else 1  # JiÅ¾nÃ­ ÄŒechy vÃ­ce nÃ¡chylnÃ©
    historical_protests = 1 if lon > 15.0 else 0  # VÃ½chodnÃ­ ÄŒechy
    
    return {
        "historical_flood_events": historical_floods,
        "historical_protest_events": historical_protests,
        "total_historical_events": historical_floods + historical_protests,
        "risk_trend": "increasing" if historical_floods > 1 else "stable"
    }

def calculate_combined_risk(river_analysis: dict, elevation_analysis: dict, historical_analysis: dict) -> dict:
    """VÃ½poÄet kombinovanÃ©ho rizika"""
    risk_score = 0
    
    # Riziko od Å™ek
    if river_analysis['risk_level'] == 'high':
        risk_score += 40
    elif river_analysis['risk_level'] == 'medium':
        risk_score += 20
    
    # Riziko od nadmoÅ™skÃ© vÃ½Å¡ky
    if elevation_analysis['flood_vulnerability'] == 'high':
        risk_score += 30
    elif elevation_analysis['flood_vulnerability'] == 'medium':
        risk_score += 15
    
    # Riziko z historickÃ½ch udÃ¡lostÃ­
    if historical_analysis['total_historical_events'] > 2:
        risk_score += 30
    elif historical_analysis['total_historical_events'] > 0:
        risk_score += 15
    
    # CelkovÃ© hodnocenÃ­
    if risk_score >= 70:
        overall_risk = "critical"
    elif risk_score >= 50:
        overall_risk = "high"
    elif risk_score >= 30:
        overall_risk = "medium"
    else:
        overall_risk = "low"
    
    return {
        "risk_score": risk_score,
        "overall_risk_level": overall_risk,
        "risk_factors": {
            "river_proximity": river_analysis['risk_level'],
            "elevation_vulnerability": elevation_analysis['flood_vulnerability'],
            "historical_events": historical_analysis['total_historical_events']
        },
        "recommendations": generate_risk_recommendations(overall_risk)
    }

def simulate_supply_chain_impact(supplier: dict, risk_stats: dict, event_type: str) -> dict:
    """Simulace dopadu na dodavatelskÃ½ Å™etÄ›zec"""
    total_events = risk_stats['total_events'] or 0
    critical_events = risk_stats['high_risk_events'] or 0
    
    # VÃ½poÄet rizika pÅ™eruÅ¡enÃ­ dodÃ¡vek
    disruption_probability = min(critical_events * 0.3, 0.9)
    
    # Dopad podle kategorie dodavatele
    category_impact = {
        'electronics': 'critical',
        'tires': 'high',
        'steering': 'high',
        'brakes': 'critical',
        'body_parts': 'medium'
    }
    
    impact_level = category_impact.get(supplier['category'], 'medium')
    
    # Simulace Äasu obnovy
    recovery_time_days = {
        'critical': 30,
        'high': 14,
        'medium': 7,
        'low': 3
    }
    
    return {
        "disruption_probability": disruption_probability,
        "impact_level": impact_level,
        "estimated_recovery_days": recovery_time_days[impact_level],
        "alternative_suppliers_needed": disruption_probability > 0.5,
        "mitigation_actions": generate_mitigation_actions(impact_level, disruption_probability)
    }

def generate_risk_recommendations(risk_level: str) -> list:
    """GenerovÃ¡nÃ­ doporuÄenÃ­ na zÃ¡kladÄ› ÃºrovnÄ› rizika"""
    recommendations = {
        'critical': [
            "OkamÅ¾itÄ› implementovat protipovodÅˆovÃ¡ opatÅ™enÃ­",
            "VytvoÅ™it zÃ¡loÅ¾nÃ­ dodavatelskÃ½ Å™etÄ›zec",
            "PÅ™esunout vÃ½robu do bezpeÄnÄ›jÅ¡Ã­ lokace",
            "Instalovat monitoring hladiny vody"
        ],
        'high': [
            "Implementovat protipovodÅˆovÃ¡ opatÅ™enÃ­",
            "VytvoÅ™it plÃ¡n evakuace",
            "ZvÃ½Å¡it pojiÅ¡tÄ›nÃ­",
            "Monitoring meteorologickÃ½ch podmÃ­nek"
        ],
        'medium': [
            "PravidelnÃ© kontroly bezpeÄnostnÃ­ch opatÅ™enÃ­",
            "Aktualizace pojiÅ¡tÄ›nÃ­",
            "Monitoring lokÃ¡lnÃ­ch rizik"
        ],
        'low': [
            "StandardnÃ­ bezpeÄnostnÃ­ opatÅ™enÃ­",
            "PravidelnÃ© kontroly"
        ]
    }
    
    return recommendations.get(risk_level, ["StandardnÃ­ opatÅ™enÃ­"])

def generate_mitigation_actions(impact_level: str, probability: float) -> list:
    """GenerovÃ¡nÃ­ mitigaÄnÃ­ch opatÅ™enÃ­"""
    actions = []
    
    if probability > 0.7:
        actions.append("OkamÅ¾itÄ› aktivovat zÃ¡loÅ¾nÃ­ dodavatele")
        actions.append("PÅ™esunout kritickou vÃ½robu")
    
    if impact_level in ['critical', 'high']:
        actions.append("ZvÃ½Å¡it bezpeÄnostnÃ­ zÃ¡soby")
        actions.append("Implementovat monitoring dodavatelskÃ©ho Å™etÄ›zce")
    
    if probability > 0.5:
        actions.append("Aktivovat krizovÃ½ management")
        actions.append("Komunikovat s dodavateli o rizicÃ­ch")
    
    return actions 